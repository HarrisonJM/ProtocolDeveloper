=========================================================
=================== What is the thing ===================
=========================================================
-- Simulation has played a vital role in system verification for a long time; however, it requires a great deal of time, and resource. But it's usefuleness and importance in software engineering has been noted in great detail by many authors (Sun & Männistö, 2012).

-- Test tools are an "addendum" to normal development and perform a task realted to but seperate to direct development (Na and Huaichang, 2015).

-- Load testing is vital to proving that web services meet the demands of its users, both in traffic and bheaviour (Draheim et al 2006)
-- Helps to locate issues in the code that might not appear under smaller load. These are errors are called "Load sensitive". (Bayan and Cangussu, 2006)

-- The rate at which transactions are conducted constitutes load. Sending this to a target for test purposes, constitutes a Load Test. (Bayan and Cangussu, 2006)
-- Stress Testing is similair to workload, however the express intention is to break the system, and to verify how it recovers. (Bayan and Cangussu, 2006)

-- Workload (characteristics and intensity), environment and , high-level metrics define a load test and its results (Malik, 2010).
-- Intensity refers to arrival rate and throuput of data (Malik, 2010).
-- All of these come together in a test report (Malik, 2010).

-- Simluating the internet proper is near impossible, due to its shear scale, impracticality and the number of nodes needed (Sumeet Kumar and Kathleen 2017).	

-- It is certainly possible to create software that facilitates the entire load testing process. And to make the results it obtains far more accurate (Yan et al, 2014).

-- It helps developers to understand their application in extreme circumstances(PR Newswire Association LLC, 2014).

-- Load testing is as vital to the testing of an application a unit testing and integration testing(Jiand & Hassan, 2015).

-- Load testing is performed on a - to some degree - implemented system as opposed to the design or architecture of the system in question (Jiand & Hassan, 2015).

-- In a similiar category to load testing is "stress testing"; the process of putting a system under incredibley extreme conditions to verify how it handles guarunteed error states (Jiand & Hassan, 2015).

-- The purpose of a load test is to help guaruntee if a given system's performance is acceptable under peak conditions. This means checking response times and resource usage and helping develoeprs, testers, managers and potential customers decide whether or not the system's performnce is acceptable ro more work needs to be done to bring it to within acceptable limits. While all this happens there are still any other factors to consider (Zhang et al, 2011).

-- As focus shifts towrads offering software as a service with offsite hosting (a.k.a "The Cloud"), more and more emphasis nmust be put on testing these systems that require incredible high throughputs due to the sheer numebr of people accessing them and the ocmplex actions that they perform. However, this also extends to making sure that a load tester can be provided/offered as-a-service (XaaS) (Shojaee et al, 2015).

-- Load testing referes to how a piece of software handles "load". Where load means just the rate of requests being received by the system (Jiang, 2015).

-- Classic server arrangements, datacenters and cloud configurations all require load testing to some degree to guaruntee their service is robust and reliable (Cico & Dika, 2014).

==========================================================
===================== Other programs =====================
==========================================================
- Mercury Interactive Continues to Dominate as Worldwide Load Testing Market Leader; Company Captures 63% of Web Load Testing Market; Leads Market for Hosted Load Testing Services
-- Mercury Interactive's LoadRunner current load testing leader (Draheim et al 2006)
-- Current software are only client-server models (Bhatia et al, 2014)
-- Limited number of scenarios (Bhatia et al, 2014)	
-- DITG, Harpoon, fudp, 2Hping and, curlLoader are currently available open source traffic generators (Bhatia et al, 2014)
-- Curlloader is relatively flexible in its use (Bhatia et al, 2014)

-- LoadUI, ApacheJmeter IBM Rational Performance Tester (Yan et al, 2014)
-- Testmaker is another WS load tester that allows concurrency testing on Amazon EC2 (Yan et al, 2014).
-- SoapUI is another very helpful tool (Shojaee et al, 2015).

- SOAPtest is noted as growing in popularity surrounding testing of vital server systems. (Grehan, 2005)

-- SURGE calculates how a user might interact with a website based on what's on each page (Hasenleithner and Ziegler, 2003)

-- AlertSite also offers a load testing service that even goes as far as to offer consultancy on how to improve their systems (PR Newswire Association LLC, 2014).

 -- Yet another tool Iometer can be be used to gauge hardware usage and test performance of storage systems without complicated testbeds (Baltazar, 1998)

==========================================================
================= Problem Identification =================
==========================================================
-- Tests often need to be parameterised and modified (Draheim et al 2006)
-- Often hard to do (Draheim et al 2006)
-- More advanced tools are needed (Draheim et al 2006)
-- Load test analysis methodology has been performed before (Malik, 2010)
-- Models can even be machine generated based on behaviour observation (Bayan and Cangussu, 2006).
-- Current tools support simple test cases with a fixed sequence of actions (Draheim et al 2006)
-- Limited number of scenarios (Bhatia et al, 2014)	
-- Current software are only client-server models (Bhatia et al, 2014)
-- As software shifts towards being offered "as a service" (-aas). Offering some sort of load tester as a service would be wise, and allow for future proofing (Yan et al, 2014).	
-- A Load tester will likely contain four major components: Test Receiver, Test Manager, Middleware Manager and a Test Runner (Yan et al, 2014).
-- Test Receiver: Receives tests to run from the tester, can also monitor tests (Yan et al, 2014).
-- Test Manager: Manages queues fo tests and dispatches them, gathering and merging test results (Yan et al, 2014).

-- Test Runner: Invokes the tests. Also analyses validity of results (Yan et al, 2014). 
-- Middleware Manager: provides and amanges testrunners for use within the system (Yan et al, 2014)

-- Giving the user the option of adjusting the size and rate of sending is beneficial. Existing approaches consist of increasing the query size, number of queries or, the rat at which queries are made (Zhang et al, 2011).

-- XML is already used by large amounts of developers and engineers inluding many protocols themselves (Garg and Lavahte, 2017).

-- JSON is not as widely supported regarding protocols and can fall over when it encounters special characters (however this is purely implementation dependent). Some solutions do not provide workflow testing or even true load testing. They can also make documentation more difficult (Garg and Lavahte, 2017)
 
-- Cross-platform running would be a boon to making sure that the most amount of people possible are reached (Garg and Lavahte, 2017).

-- Other software already offers a great deal of different testing approaches and services for maximum beneficial interaction (Garg and Lavahte, 2017).

-- Allowing for scripting support of any kind would be very beneficial in making sure that the process can be automated with minimal user interaction and to better fit into an AGILE work flow (Shojaee et al, 2015).

-- The are several limitaions to load testing currently: Cost-effectiveness, increasing input size may be very costly and increasing input size may just force the system to continually perform the same computation (Zhang et al, 2011).

=========================================================
======================= Use Cases =======================
=========================================================
-- Artificial traffic generation is often the only practical way to really verify the running of a service (Bhatia et al, 2014).
-- Hardware traffic generation often leads to greater packet drop at the target (Bhatia et al, 2014)
-- Hardware is faster but also comes at a greater cost (Bhatia et al, 2014)
-- Generating precise traffic allows greater control (Bhatia et al, 2014)

-- Load testing can turn up a variety of problems including: memory leaks, error keywords, deadlocks, unhealthy system states and throughput problems (Jiand & Hassan, 2015).

-- Testing must be performed even on the smallest servers and services. Without testing significant amounts of resources coudl be lost to minor bugs cropping up and taking out the entire system when they could have been found during a simple load testing phase during development/setup (Koh et al, 2018).

-- Large scale systems, especially so, nmust be tested to make sure that they can still service the millions of simultaneous requests every second (Jiang, 2015).

-- As the demand on servers increases as more things become cloud based, it will be more and more vital to test these systems to verify they still maintain maximum throughput. Especially as users attempt to store and access files on these services. (Baltazar, 1998)

=========================================================
================= How should it be done =================
=========================================================

-- Load testing should be performed regularly to make sure that resources are correctly provisioned (Draheim et al 2006).

-- Different Modes need to be offered for proper testing. Static, step and maximal testing are three such methods. Static runs for a specific load. 
Step runs for measuring usability under a load span. Maximal load to determine upper limits (Yan et al, 2014).

 -- Load testing works best with lots of different entities fully flexing a system (Chapuis & Garbinato, 2017).

 -- AGILE development works best with higher amounts of automation and as dterministic results as possible (Garg and Lavahte, 2017).
 -- However different runs of the same test may produce different results anyway (non-dterministic) so it would be good to limit these situations as much as possible (Hwang et al, 2004).
 
 -- No matter the system being tested a "client/server" model will be used for all interactions (Hwang et al, 2004).

 -- Manually testing web services would be incredibly labourious, slow and expesnive (Garg and Lavahte, 2017).

=========================================================
================ Requirements and Design ================
=========================================================
-- It is impreative that running data is recorded throughout the running the of the load test. Both by the traffic generator and the system under test (Jiang, 2015).

-- Real user data can (and should) be used to model traffic. However such models are less versatile than stochastic ones. (Draheim et al 2006)
-- Script driven approches are common, but visual editors massively increase usability.
Realistic Load Testing of Web Applications (Draheim et al 2006)

-- Reconfigurability for a variety of connections. Low cost, low resource would be a signifcant boon, however using the resources as efficiently as possible is key.
Traffic load co-ordination would also help to improve results and efficency. Traffic aggregation would also be beneficial to make sure all traffic acts on a single interface at the target.	Monitoring the traffic is also a good feature to have. (Bhatia et al, 2014)

-- Another structure would involve: Input identification, controller tuning and a controller. Input Identification involves finding inputs that affect the resource of interest. Controller tuning involves figuroing out the internal parameters of the chosen controller. The controller itself drives the testcases to what load level is wanted. (Bayan and Cangussu, 2006)

-- [Fig 1] looks good. Lift it. (Draheima and Weber, 2005)

-- Pseudo random generators are very good for the purposes of this program (Akhshani et al 2017).

-- The algorithm for constructing a random number generator based on quantum chaotic maps can also be used to create a good chaos model from which to work. 
Only using user activity graphs instead, to better try to model peak times. (Akhshani et al 2017)

-- User interaction can be modelled as a bipartite state transition diagram (Draheim et al 2006)

-- Geographically distributed instances would improve the results per test task (Yan et al, 2014).


-- Even though the systems themselves would need testing; load testing from a cloud-based platform would be entirely possible (and preferable in some situations where location of requests is important) (Shojaee et al, 2015).
-- Large amounts of concurrency within each instance would be good as the loads can be very large, and the taffic could be very high (Yan et al, 2014).

-- It is important that the user designs loads well, but mor eimportantly that the software interprets them accurately, this is also a practice left up to the user in creating the plugin (Jiand & Hassan, 2015).

-- Being able to scale to simulate potentially millions of requests would be incredibly beneficial to the testing of the software (Jiand & Hassan, 2015).

-- Current load testers have a very limited number of virutal users and testing many different confgiurations is difficult and time consuming. Having the ability to scale the software up and up depending ont he users' needs would be an incredible feat and highly desireable (Shojaee et al, 2015).

-- Anomolies should be able to be detected by Performance metrics and execution logs (Jiand & Hassan, 2015)

-- Making sure messages are routed to the correct threads while the system is running is very important as messages can be interleaved by the underlying asynchronous operations (Koh et al, 2018).

-- Making suer that the software can run on a variety of system's will help to maximise its customer base. This can best be acheived by making sure that only the stnadard libraries are adghered to mostly (Baltazar, 1998).

-- There will be three steps to laod testing for the user when it comes to using the software after the plugins ahve been created: designing it, executing it and, analyzing the results (Jiang, 2015).

-- Being able to build the perfect laod testing system from scratch would help developers to get exactly what they want out of a laod tester to make suer that they're software is tested exactly as they need it to be (Grehan, 2005).

 -- However it is important that the software adheres to some basic hardware requirements to make sure it doesn't completely excede anything that might be able to run it, though assuming the software will mostly be run on servers, resource usage shouldnt' be too bad. However if we exceed the tester's limits we may invalidate the test results (Garg and Lavahte, 2017)

 -- Having a variety of ways to check on and use the software would be very useful, including a full UI, A task monitor, and a configuration manager (Na and Huaichang, 2015)

-- An API for interaction would also be very useful as it would allow many different ways of interacting with the system for different purposes (Na and Huaichang, 2015)

 -- Being able to extend the program beyond its basic function would be an incredibley useful feature and is already in place in many modern systems such as Robot (Na and Huaichang, 2015).
 
-- Other great fatures to have that are present in other systems are custom load testing "Scripts", specific agents, environment switching, test debugging and performance monnitoring (Garg and Lavahte, 2017).

-- Maximising what tools it can integrate would be a great help to supporting the AGILE workflow too, with integration with systems such as Maven, Hudson, Navigator, Junit, ApacheAnt (Garg and Lavahte, 2017).
- 
